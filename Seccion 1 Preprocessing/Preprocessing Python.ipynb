{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Preprocessing </h2>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   Country   Age   Salary Purchased\n0   France  44.0  72000.0        No\n1    Spain  27.0  48000.0       Yes\n2  Germany  30.0  54000.0        No\n3    Spain  38.0  61000.0        No\n4  Germany  40.0      NaN       Yes",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Age</th>\n      <th>Salary</th>\n      <th>Purchased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>France</td>\n      <td>44.0</td>\n      <td>72000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Spain</td>\n      <td>27.0</td>\n      <td>48000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Germany</td>\n      <td>30.0</td>\n      <td>54000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Spain</td>\n      <td>38.0</td>\n      <td>61000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Germany</td>\n      <td>40.0</td>\n      <td>NaN</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet = pd.read_csv(\"./Data/Data.csv\")\n",
    "DataSet.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['France', 44.0, 72000.0],\n       ['Spain', 27.0, 48000.0],\n       ['Germany', 30.0, 54000.0],\n       ['Spain', 38.0, 61000.0],\n       ['Germany', 40.0, nan],\n       ['France', 35.0, 58000.0],\n       ['Spain', nan, 52000.0],\n       ['France', 48.0, 79000.0],\n       ['Germany', 50.0, 83000.0],\n       ['France', 37.0, 67000.0]], dtype=object)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = DataSet.iloc[:, :-1].values\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n      dtype=object)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = DataSet.iloc[:, -1].values\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SimpleImputer Cambia los valores especificados con la estrategia que se le ha puesto, esto con el fin de no desperdiciar data que puede ser\n",
    "relevante en el análisis sino que es procesada de una mejor forma para asignar un valor deseado."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['France', 44.0, 72000.0],\n       ['Spain', 27.0, 48000.0],\n       ['Germany', 30.0, 54000.0],\n       ['Spain', 38.0, 61000.0],\n       ['Germany', 40.0, 63777.77777777778],\n       ['France', 35.0, 58000.0],\n       ['Spain', 38.77777777777778, 52000.0],\n       ['France', 48.0, 79000.0],\n       ['Germany', 50.0, 83000.0],\n       ['France', 37.0, 67000.0]], dtype=object)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "imputer = imputer.fit(X[:, 1:])\n",
    "X[:, 1:] = imputer.transform(X[:, 1:])\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Codificar Datos Categoricos </h3>\n",
    "La idea es mapear los diferentes datos categoricos para tener una representación numerica de estos datos, por ello\n",
    "se hace una matriz de elección, lo cual agrega tantas columnas como datos diferentes existan, en este caso se agregan 3 columnas.\n",
    "Esta matriz se conoce como Variables Dummy o OneHotEncoder.\n",
    "Para la matriz X se hace:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.40000000e+01,\n        7.20000000e+04],\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.70000000e+01,\n        4.80000000e+04],\n       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 3.00000000e+01,\n        5.40000000e+04],\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.80000000e+01,\n        6.10000000e+04],\n       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e+01,\n        6.37777778e+04],\n       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.50000000e+01,\n        5.80000000e+04],\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.87777778e+01,\n        5.20000000e+04],\n       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.80000000e+01,\n        7.90000000e+04],\n       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 5.00000000e+01,\n        8.30000000e+04],\n       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.70000000e+01,\n        6.70000000e+04]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [0])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "X = np.array(ct.fit_transform(X), dtype=np.float)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Y para el vector de etiquetas Y:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> División de DataSet en entrenamiento y test </h3>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Escalado de variables </h3>\n",
    "Es indispensable estandarizar y normalizar las características para que los modelos de predicción no se incline a unas características\n",
    "sino permita disernir entre las diferentes existentes.\n",
    "Se pueden escalar las variables doomies para tener coherencia con el escalado de las otras features, sin embargo también se le pueden dejar\n",
    "tal cual están ya que estas muestran una variable categorica que muestra una clase de una feature, está a decisión de quien lo implemente."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "SS_X = StandardScaler()\n",
    "X_train = SS_X.fit_transform(X_train)\n",
    "X_test = SS_X.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}